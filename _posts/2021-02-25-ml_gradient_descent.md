---
title: "[Machine Learning] 경사하강법(Gradient Descent)"
category: Machine Learning
use_math: true
---

## 경사하강법(Gradient Descent)
- ML에서 모든 학습의 원리
- ML 모델의 파라미터를 업데이트하는 원리
- 함수에서 파라미터에 기울기(경사)를 빼면서 하강하여 오차값의 최소가 되는 지점에 이를 때까지 반복시키는 방법
- 어느 지점이든 미분값을 빼주기만 하면, 오차가 작은 방향으로 이동할 것임

### 공식
![](/assets/images/posts/ml/gradient_descent.png)

## 실습
<a href="https://colab.research.google.com/drive/13Nt7H2qO0FMbyH64ePqm8ouzy72SRKig?usp=sharing">Google Colab 참조</a>