---
title: "[Practical Statistics] 회귀 분석(Regression Analysis)"
category: Practical Statistics
use_math: true
---

# Regression Analysis(회귀 분석)
> 과거의 결과값을 기준으로 미래의 결과값을 예측하는 방법<br>
> 독립변수(x)로 종속변수(y)를 예측하는 것

## 1) 인과관계 성립조건 3가지
### (1) 두 변수(현상)가 동시에 변화해야 한다.
- 공분산, 상관계수

### (2) 원인변수(독립변수)가 선행되어야 한다.
- 원인변수(독립변수, x)는 결과변수(종속변수, y) 보다 선행되어야 한다.
- 예 : 광고비 지출(x)에 대한 매출 변화(y)

### (3) 기타 요인이 없어야 한다.
- 오로지 원인변수(x) 만이 결과변수(y)를 변화시켜야 하고, 제 3의 변수가 영향을 줄 가능성을 모두 제거해야 한다.
- 통제된 실험환경 및 분석환경, 변수 통제
- 사실, 기타 요인을 완벽하게 통제할 수 없다.

## 2) 회귀(Regression)
> 미래에 발생할 결과값이 '과거의 평균으로 돌아간다'

## 3) 회귀식
> $y ~ ax + b$ 에서 최소제곱법으로 회귀계수를 계산

- $x$의 값에 따라 $y$값이 결정된다.
    - $y$ : 종속변수(반응변수)
    - $x$ : 독립변수(설명변수)

## 4) 최소제곱법(Ordinary Least Squares)
> 회귀식의 파라미터값을 추정하는 방법 중 하나

$SST = SSR + SSE$

- SST(Total Sum of Squared)
  - y의 전체 변동
  - $\sum(y-\bar{y})^2$
- SSR(Regression Sum of Squared)
  - 회귀 직선으로 설명되는 변동
  - $\sum(\hat{y}-\bar{y})^2$
- SSE(Error Sum of Squared)
  - 회귀 직선으로 설명 불가능한 변동
  - $\sum(y-\hat{y})^2$

## 5) 결정계수(Coefficient of Determination)
> 회귀모형의 설명력<br>
> X로 Y의 변동을 얼마나 설명할 수 있는가? 

- 회귀모델의 적합도 평가를 위해 사용되는 계수
- 종속변수 예측값과 실제값의 상관계수 제곱값
- 0 ~ 1의 범위를 가지며, 1에 가까울수록 선형회귀모델의 설명력이 높다.
- 독립변수 개수가 증가하면 결정계수값이 증가함

$R^2 = \cfrac{SSR}{SST} = 1 - \cfrac{SSE}{SST}$

## 6) 수정된 결정계수(Adjusted $R^2$)
> 다중회귀분석에서 사용되는 결정계수

- 독립변수의 개수가 증가함에 따라 $R^2$ 값이 증가하는 문제가 발생하므로, 수정하여 사용이 필요함
- 독립변수 개수 $p$ 를 분모에 위치시켜 $R^2$ 값이 증가되는 영향을 감소시킴

$Adjusted\ R^2 = 1 - \cfrac{n-1}{(n-p-1)(1-R^2)}$

## 7) 회귀 분석의 종류

### (1) 단일 회귀 분석
> 종속변수에 영향을 주는 독립변수가 1개인 회귀 분석

### (2) 다중 회귀 분석
> 종속변수에 영향을 주는 독립변수가 여러 개인 회귀 분석

#### 다중공선성(Multicollinearity)
> 독립변수가 다른 여러개의 독립변수들로 잘 예측(설명)되는 경우

두 변수의 상관관계가 매우 높을 경우, 두 변수는 매우 유사한 정보를 가지고 있다고 볼 수 있다.

이런 경우 두 변수에는 다중공선성이 있다고 한다.

##### 다중공선성 진단
- 분산팽창계수(Variance Ination Factor, VIF)
  - 엄밀한 기준은 없으나 10보다 크면 다중공선성이 있다고 판단
  - 5를 기준으로 하기도 함
  
##### 다중 공선성 해결
- VIF가 큰 독립변수를 제거 후 모델링

<br>

## 실습
- <a href="https://colab.research.google.com/drive/1ydkR3HGsG4PLz-aevCmP9IDXkHXYgcLY?usp=sharing">회귀 분석</a>